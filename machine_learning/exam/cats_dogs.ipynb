{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projektabgabe: Machine Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, optimizers, Sequential, regularizers\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der `cats_vs_dogs` Datensatz besteht aus 23.262 Bildern von Katzen und Hunden. Die Bilder sind in 2 Klassen aufgeteilt: Katzen und Hunde (gelabelter Datensatz). Der Datensatz beinhaltet außerdem 1738 korrupte Bilder, die automatisch entfernt wurden.\n",
    "\n",
    "`split=[\"train[0:16000]\", \"train[16000:20000]\"]` teilt den Datensatz in 2 Teile auf. Der erste Teil wird für das Training verwendet, der zweite Teil für die Validierung. Mittels `shuffle_files=True` werden die Bilder zufällig gemischt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load('CatsVsDogs', split=[\"train[:80%]\", \"train[80%:]\"], shuffle_files=True, as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_examples = tfds.visualization.show_examples(ds_train, ds_info, rows=4, cols=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_gray(image, label):\n",
    "    return tf.image.rgb_to_grayscale(image), label\n",
    "\n",
    "def normalize_img(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "def resize_img(image, label):\n",
    "    return tf.image.resize(image, (128, 128)), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.map(convert_to_gray, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.map(resize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.batch(32)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(convert_to_gray, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.map(resize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(64)\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/uysimty/keras-cnn-dog-or-cat-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(), loss=keras.losses.BinaryCrossentropy(), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = datetime.now().strftime(\"%d%m-%H%M\")\n",
    "\n",
    "checkpoint_path = f\"checkpoints/cats-dogs-{time}.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoints = ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
    "stop = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "callbacks = [checkpoints, stop, lr_reduce]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(ds_train, validation_data=ds_test, epochs=20, callbacks=callbacks, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "print(history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest = history_df[\"val_accuracy\"].max().round(2)\n",
    "\n",
    "model.save(f\"cats-dogs-{time}-{highest}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 7))\n",
    "\n",
    "sns.lineplot(x=history_df.index, y=history_df[\"loss\"], ax=axs[0], label=\"loss\")\n",
    "sns.lineplot(x=history_df.index, y=history_df[\"val_loss\"], ax=axs[0], label=\"val_loss\")\n",
    "sns.lineplot(x=history_df.index, y=history_df[\"accuracy\"], ax=axs[1], label=\"accuracy\")\n",
    "sns.lineplot(x=history_df.index, y=history_df[\"val_accuracy\"], ax=axs[1], label=\"val_accuracy\")\n",
    "\n",
    "axs[0].set_title(\"Loss\")\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "\n",
    "axs[0].set_xlabel(\"Epochen\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "\n",
    "axs[1].set_xlabel(\"Epochen\")\n",
    "axs[1].set_ylabel(\"Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "00155b37fbb991365d0ee05c40a31a80e0b75de72a8bd7547540e678c5c3c0a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
