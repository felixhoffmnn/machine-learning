{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Marketing Data Set\n",
    "\n",
    "Im folgenden wird der `Bank Marketing Data Set` aus dem UCI Machine Learning Repository verwendet. Dieser Datensatz enthält Informationen über Kunden, die ein Bankkonto eröffnen möchten. Ziel ist es, ein Modell zu trainieren, das vorhersagen kann, ob ein Kunde ein Konto eröffnen wird oder nicht.\n",
    "\n",
    "**Matrikel-Nr.**: 1946566"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import requests, zipfile, io\n",
    "\n",
    "sns.set(\"notebook\", font_scale=1.5, style=\"white\", rc={\"figure.figsize\":(20, 8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"./\")\n",
    "\n",
    "req = requests.get(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip\")\n",
    "\n",
    "zip_file = zipfile.ZipFile(io.BytesIO(req.content))\n",
    "zip_file.extractall(data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis 1/2\n",
    "\n",
    "---\n",
    "\n",
    "Aus den Datensatz gehen folgende Spalten hervor:\n",
    "\n",
    "**Kundendaten**:\n",
    "\n",
    "- `age`: Alter des Kunden\n",
    "- `job`: Beruf des Kunden\n",
    "- `marital`: Familienstand des Kunden\n",
    "- `education`: Bildungsstand des Kunden\n",
    "- `default`: Ob der Kunde ein Kreditkartenkonto hat\n",
    "- `balance`: Kontostand des Kunden\n",
    "- `housing`: Ob der Kunde ein Hypothekarkredit hat\n",
    "- `loan`: Ob der Kunde ein Privatkredit hat\n",
    "\n",
    "**Letzter Kontakt**:\n",
    "\n",
    "- `contact`: Art des letzten Kontakts\n",
    "- `day`: Tag des letzten Kontakts\n",
    "- `month`: Monat des letzten Kontakts\n",
    "- `duration`: Dauer des letzten Kontakts in Sekunden\n",
    "\n",
    "**Andere**:\n",
    "\n",
    "- `campaign`: Anzahl der Kontakte während dieser Kampagne\n",
    "- `pdays`: Anzahl der Tage seit dem letzten Kontakt zu einem anderen Kunden\n",
    "- `previous`: Anzahl der Kontakte zu einem anderen Kunden vor dieser Kampagne\n",
    "- `poutcome`: Ergebnis der vorherigen Kampagne\n",
    "- `y`: Ob der Kunde ein Konto eröffnet hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = pd.read_csv(data_path / \"bank.csv\", sep=';')\n",
    "df_large = pd.read_csv(data_path / \"bank-full.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus dem Datensatz geht hervor, dass die Kunden ein **Durschnittsalter** von 41 Jahren haben. Außerdem haben die Kunden Durchschnittlich circa $ `1360` auf dem Konto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "df_large.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "any(df_large.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_col = [col for col in df_large.columns if df_large[col].nunique() <= 15]\n",
    "category_col_values = {\n",
    "    col: df_large[col].value_counts().to_dict() \n",
    "    for col in df_large.columns if df_large[col].nunique() <= 15\n",
    "}\n",
    "\n",
    "with open(data_path / \"category_col_values.json\", \"w\") as f:\n",
    "    json.dump(category_col_values, f)\n",
    "    \n",
    "print(category_col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_types = {\n",
    "        \"age\": np.int8,\n",
    "        \"job\": \"category\",\n",
    "        \"marital\": \"category\",\n",
    "        \"education\": \"category\",\n",
    "        \"default\": \"category\",\n",
    "        \"balance\": np.int32,\n",
    "        \"housing\": \"category\",\n",
    "        \"loan\": \"category\",\n",
    "        \"contact\": \"category\",\n",
    "        \"day\": np.int8,\n",
    "        \"month\": \"category\",\n",
    "        \"duration\": np.int16,\n",
    "        \"campaign\": np.int8,\n",
    "        \"pdays\": np.int16,\n",
    "        \"previous\": np.int8,\n",
    "        \"poutcome\": \"category\",\n",
    "        \"y\": \"category\"\n",
    "    }\n",
    "    \n",
    "    df = df.astype(df_types)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = prepare_pipeline(df_large.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.info(memory_usage='deep')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"default\"] = df[\"default\"].map({\"no\": 0, \"yes\": 1}).astype(np.int8)\n",
    "    df[\"housing\"] = df[\"housing\"].map({\"no\": 0, \"yes\": 1}).astype(np.int8)\n",
    "    df[\"loan\"] = df[\"loan\"].map({\"no\": 0, \"yes\": 1}).astype(np.int8)\n",
    "    df[\"month\"] = df[\"month\"].map({\n",
    "        \"jan\": 1, \"feb\": 2, \"mar\": 3, \"apr\": 4, \"may\": 5, \"jun\": 6,\n",
    "        \"jul\": 7, \"aug\": 8, \"sep\": 9, \"oct\": 10, \"nov\": 11, \"dec\": 12\n",
    "    }).astype(np.int8)\n",
    "    df[\"y\"] = df[\"y\"].map({\"no\": 0, \"yes\": 1}).astype(np.int8)\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=[\"job\", \"education\", \"poutcome\", \"marital\", \"contact\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc = encode_pipeline(df_prep.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc.info(memory_usage='deep')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis 2/2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subscribers - Term Deposit\n",
    "\n",
    "Aus der Grafik wir ersichtlich, dass es deutlich mehr Kunden gibt, die kein Konto bei der Bank besitzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_large, x=\"y\", discrete=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Properties\n",
    "\n",
    "Die Menge der Kunden in dem Alter von `25 - 60` Jahren ist sehr hoch. Dies könnte daran liegen, dass dies die Altersgruppe ist, in der die meisten Menschen arbeiten und somit ein Konto bei der Bank benötigen.\n",
    "\n",
    "Der Job, Ehestatus und der Bildung variiert sehr stark von Kategorie zu Kategorie. Die Trends, ob ein Kunde ein Konto besitzt oder nicht, sind unabhängig von diesen Eigenschaften sehr ähnlich.\n",
    "\n",
    "Die meisten Kunden sind im Bereich *Management*, *Blue Collar* und *Techniker* tätig.\n",
    "\n",
    "Die meisten Kunden sind außerdem verheiratet und haben einen höheren Bildungsabschluss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(25, 25))\n",
    "\n",
    "sns.histplot(df_large, x=\"age\", ax=axs[0][0])\n",
    "sns.countplot(x=\"job\", hue=\"y\", data=df_large, ax=axs[0][1])\n",
    "sns.countplot(x=\"marital\", hue=\"y\", data=df_large, ax=axs[1][0])\n",
    "sns.countplot(x=\"education\", hue=\"y\", data=df_large, ax=axs[1][1])\n",
    "\n",
    "axs[0][0].set_title(\"Age\")\n",
    "axs[0][1].set_title(\"Job\")\n",
    "axs[1][0].set_title(\"Marital\")\n",
    "axs[1][1].set_title(\"Education\")\n",
    "\n",
    "axs[0][1].tick_params(axis='x', rotation=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(df_large, x=\"job\", y=\"age\", hue=\"y\")\n",
    "\n",
    "plt.title(\"Age by Job\")\n",
    "plt.xticks(rotation=35)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loans and Credits\n",
    "\n",
    "Wenn ein Kunde ein `default_credit` haben, gibt es keinen Kunden der ebenfalls ein `term_deposit` hat.\n",
    "\n",
    "Wenn ein Kunde einen Kredit auf sein Haus aufgenommen hat, ist das Verhältnis von Kunden mit einem `term_deposit` leicht höher. Außerdem lässt sich feststellen, dass es mehr Kunden mit einen Kredit auf ihrem Haus gibt, als ohne.\n",
    "\n",
    "Es gibt deutlich mehr Kunden ohne einen `personal_loan` als mit einem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(25, 25))\n",
    "\n",
    "sns.countplot(x=\"default\", hue=\"y\", data=df_large, ax=axs[0][0])\n",
    "sns.countplot(x=\"housing\", hue=\"y\", data=df_large, ax=axs[0][1])\n",
    "sns.countplot(x=\"loan\", hue=\"y\", data=df_large, ax=axs[1][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"duration\", y=\"balance\", hue=\"marital\", data=df_large)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "Die Korrelation zwischen der Dauer des Gesprächs und ob ein Kunde ein Konto eröffnet korrelieren zu stark miteinander. Dies könnte daran liegen, dass die Kunden, die ein Konto eröffnen, länger mit dem Bankberater sprechen, um mehr Informationen zu erhalten. \n",
    "\n",
    "**Columns to Drop**:\n",
    "\n",
    "- `duration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_enc.iloc[:, 0:13].corr()\n",
    "mask = np.zeros_like(corr_matrix)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(corr_matrix, mask=mask, square=True, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_corr = []\n",
    "\n",
    "for col in corr_matrix.columns:\n",
    "    for row in corr_matrix.index:\n",
    "        if row != col:\n",
    "            collected_corr.append((col, row, corr_matrix.loc[row, col]))\n",
    "            \n",
    "df_collected_corr = pd.DataFrame(collected_corr, columns=[\"col1\", \"col2\", \"corr\"])\n",
    "df_collected_corr[\"abs_corr\"] = df_collected_corr[\"corr\"].abs()\n",
    "df_collected_corr.sort_values(\"abs_corr\", ascending=False, inplace=True)\n",
    "\n",
    "top_collected = df_collected_corr[:20]\n",
    "bayes_filter_1 = top_collected[\"col1\"].value_counts()\n",
    "bayes_filter_2 = top_collected[\"col2\"].value_counts()\n",
    "\n",
    "bayes_filter = pd.concat([bayes_filter_1, bayes_filter_2], axis=1).fillna(0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_corr = pd.DataFrame(corr_matrix[\"y\"])\n",
    "y_corr[\"corr_abs\"] = y_corr[\"y\"].abs()\n",
    "y_corr = y_corr.sort_values(by=\"corr_abs\", ascending=False)\n",
    "y_corr[1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_naive_bias = y_corr[1:11].index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "Um die Trainingszeit zu verkürzen, wird der kleinere Datensatz (`bank.csv`) für das Training und Modelling verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# TODO: Add more columns to drop\n",
    "drop_columns = [\"y\", \"pdays\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep_model = prepare_pipeline(df_small.copy())\n",
    "df_enc_model = encode_pipeline(df_prep_model.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any(df_enc_model.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_enc_model.drop(drop_columns, axis=1)\n",
    "X_train_scaled = StandardScaler().fit_transform(X_train[[\"age\", \"balance\", \"day\", \"campaign\", \"pdays\", \"previous\"]])\n",
    "\n",
    "Y_train = df_enc_model[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train_scaled, x_test_scaled, y_train, y_test = train_test_split(X_train_scaled, Y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_count = pd.DataFrame([y_train.value_counts(), y_test.value_counts()], index=[\"train\", \"test\"])\n",
    "df_y_count[\"ratio\"] = df_y_count[1] / df_y_count[0]\n",
    "\n",
    "df_y_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "# Lazy Predict is a handy tool to test multiple models\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "collected_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_clf_results, _ = lazy_clf.fit(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_clf_results.sort_values(by=\"Accuracy\", ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_cv_scores = cross_validate(ada_clf, X_train, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"AdaBoost\"] = {key: value.mean() for key, value in ada_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_cv_scores = cross_validate(ada_clf, X_train_scaled, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"AdaBoost_scaled\"] = {key: value.mean() for key, value in ada_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_test, ada_clf.fit(x_train, y_train).predict(x_test)), display_labels=[\"no\", \"yes\"]).plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_cv_scores = cross_validate(log_clf, X_train, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"GradientBoosting\"] = {key: value.mean() for key, value in log_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_cv_scores = cross_validate(log_clf, X_train_scaled, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"GradientBoosting_scaled\"] = {key: value.mean() for key, value in log_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_test, log_clf.fit(x_train, y_train).predict(x_test)), display_labels=[\"no\", \"yes\"]).plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_cv_scores = cross_validate(rand_clf, X_train, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"RandomForest\"] = {key: value.mean() for key, value in rand_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_cv_scores = cross_validate(rand_clf, X_train_scaled, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"RandomForest_scaled\"] = {key: value.mean() for key, value in rand_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_test, rand_clf.fit(x_train, y_train).predict(x_test)), display_labels=[\"no\", \"yes\"]).plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_cv_scores = cross_validate(gradient_clf, X_train, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"GradientBoosting\"] = {key: value.mean() for key, value in gradient_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_cv_scores = cross_validate(gradient_clf, X_train_scaled, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"GradientBoosting_scaled\"] = {key: value.mean() for key, value in gradient_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_test, rand_clf.fit(x_train, y_train).predict(x_test)), display_labels=[\"no\", \"yes\"]).plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cv_scores = cross_validate(svm_clf, X_train, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"SVM\"] = {key: value.mean() for key, value in svm_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cv_scores = cross_validate(svm_clf, X_train_scaled, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"SVM_scaled\"] = {key: value.mean() for key, value in svm_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_test, svm_clf.fit(x_train, y_train).predict(x_test)), display_labels=[\"no\", \"yes\"]).plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes\n",
    "\n",
    "Zuerst wird Naive Bayes auf dem gesamten Datensatz trainiert und anschließend auf dem bereinigten Datensatz. Für den bereinigten Datensatz werden die Spalten mit vielen und hohen Korrelationen entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bayes = X_train.drop(filter_naive_bias.drop(\"duration\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_cv_scores = cross_validate(gaussian_clf, X_train, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"GaussianNB\"] = {key: value.mean() for key, value in gaussian_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gussian_cv_scores = cross_validate(gaussian_clf, X_train_scaled, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"GaussianNB_scaled\"] = {key: value.mean() for key, value in gussian_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_cv_scores = cross_validate(gaussian_clf, X_train_bayes, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"GaussianNB_cleaned\"] = {key: value.mean() for key, value in gaussian_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_test, gaussian_clf.fit(x_train, y_train).predict(x_test)), display_labels=[\"no\", \"yes\"]).plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_columns = {\n",
    "    \"test_accuracy\": \"Accuracy\",\n",
    "    \"test_precision\": \"Precision\",\n",
    "    \"test_recall\": \"Recall\",\n",
    "    \"test_f1\": \"F1\",\n",
    "    \"test_roc_auc\": \"ROC AUC\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_random = pd.DataFrame(rand_clf.fit(X_train, Y_train).feature_importances_, index=X_train.columns, columns=[\"Importance\"]).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "important_random.sort_values(\"Importance\", ascending=False)[:10].plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame.from_dict(collected_results, orient='index').rename(columns=renamed_columns)\n",
    "df_results.sort_values(by=\"Accuracy\", ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    rand_clf,\n",
    "    param_grid={\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [2, 3, 5, 7],\n",
    "        \"min_samples_split\": [2, 3, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 3, 5],\n",
    "    },\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "00155b37fbb991365d0ee05c40a31a80e0b75de72a8bd7547540e678c5c3c0a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
