{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Marketing Data Set\n",
    "\n",
    "Im folgenden wird der `Bank Marketing Data Set` aus dem UCI Machine Learning Repository verwendet. Dieser Datensatz enthält Informationen über Kunden, die ein Bankkonto eröffnen möchten. Ziel ist es, ein Modell zu trainieren, das vorhersagen kann, ob ein Kunde ein Konto eröffnen wird oder nicht.\n",
    "\n",
    "**Matrikel-Nr.**: 1946566\n",
    "\n",
    "**Requirements**:\n",
    "\n",
    "- `seaborn`\n",
    "- `scikit-learn`\n",
    "- `lazypredict` ([Docs](https://lazypredict.readthedocs.io/en/stable/readme.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import requests, zipfile, io\n",
    "\n",
    "sns.set(\"notebook\", font_scale=1.5, style=\"white\", rc={\"figure.figsize\":(20, 8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"./\")\n",
    "\n",
    "req = requests.get(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip\")\n",
    "\n",
    "zip_file = zipfile.ZipFile(io.BytesIO(req.content))\n",
    "zip_file.extractall(data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis 1/2\n",
    "\n",
    "---\n",
    "\n",
    "Aus den Datensatz gehen folgende Spalten hervor:\n",
    "\n",
    "**Kundendaten**:\n",
    "\n",
    "- `age`: Alter des Kunden\n",
    "- `job`: Beruf des Kunden\n",
    "- `marital`: Familienstand des Kunden\n",
    "- `education`: Bildungsstand des Kunden\n",
    "- `default`: Ob der Kunde ein Kreditkartenkonto hat\n",
    "- `balance`: Kontostand des Kunden\n",
    "- `housing`: Ob der Kunde ein Hypothekarkredit hat\n",
    "- `loan`: Ob der Kunde ein Privatkredit hat\n",
    "\n",
    "**Letzter Kontakt**:\n",
    "\n",
    "- `contact`: Art des letzten Kontakts\n",
    "- `day`: Tag des letzten Kontakts\n",
    "- `month`: Monat des letzten Kontakts\n",
    "- `duration`: Dauer des letzten Kontakts in Sekunden\n",
    "\n",
    "**Andere**:\n",
    "\n",
    "- `campaign`: Anzahl der Kontakte während dieser Kampagne\n",
    "- `pdays`: Anzahl der Tage seit dem letzten Kontakt zu einem anderen Kunden\n",
    "- `previous`: Anzahl der Kontakte zu einem anderen Kunden vor dieser Kampagne\n",
    "- `poutcome`: Ergebnis der vorherigen Kampagne\n",
    "- `y`: Ob der Kunde ein Konto eröffnet hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = pd.read_csv(data_path / \"bank.csv\", sep=';')\n",
    "df_large = pd.read_csv(data_path / \"bank-full.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus dem Datensatz geht hervor, dass die Kunden ein **Durschnittsalter** von 41 Jahren haben. Außerdem haben die Kunden Durchschnittlich circa $ `1360` auf dem Konto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "df_large.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "any(df_large.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_col = [col for col in df_large.columns if df_large[col].nunique() <= 15]\n",
    "category_col_values = {\n",
    "    col: df_large[col].value_counts().to_dict() \n",
    "    for col in df_large.columns if df_large[col].nunique() <= 15\n",
    "}\n",
    "\n",
    "with open(data_path / \"category_col_values.json\", \"w\") as f:\n",
    "    json.dump(category_col_values, f)\n",
    "    \n",
    "print(category_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large[\"y\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small[\"y\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_types = {\n",
    "        \"age\": np.int8,\n",
    "        \"job\": \"category\",\n",
    "        \"marital\": \"category\",\n",
    "        \"education\": \"category\",\n",
    "        \"default\": \"category\",\n",
    "        \"balance\": np.int32,\n",
    "        \"housing\": \"category\",\n",
    "        \"loan\": \"category\",\n",
    "        \"contact\": \"category\",\n",
    "        \"day\": np.int8,\n",
    "        \"month\": \"category\",\n",
    "        \"duration\": np.int16,\n",
    "        \"campaign\": np.int8,\n",
    "        \"pdays\": np.int16,\n",
    "        \"previous\": np.int8,\n",
    "        \"poutcome\": \"category\",\n",
    "        \"y\": \"category\"\n",
    "    }\n",
    "    \n",
    "    df = df.astype(df_types)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = prepare_pipeline(df_large.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.info(memory_usage='deep')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"default\"] = df[\"default\"].map({\"no\": 0, \"yes\": 1}).astype(np.int8)\n",
    "    df[\"housing\"] = df[\"housing\"].map({\"no\": 0, \"yes\": 1}).astype(np.int8)\n",
    "    df[\"loan\"] = df[\"loan\"].map({\"no\": 0, \"yes\": 1}).astype(np.int8)\n",
    "    df[\"y\"] = df[\"y\"].map({\"no\": 0, \"yes\": 1}).astype(np.int8)\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=[\"job\", \"education\", \"poutcome\", \"marital\", \"contact\", \"month\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc = encode_pipeline(df_prep.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc.info(memory_usage='deep')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis 2/2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subscribers - Term Deposit\n",
    "\n",
    "Aus der Grafik wir ersichtlich, dass es deutlich mehr Kunden gibt, die kein Konto bei der Bank besitzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_large, x=\"y\", discrete=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Properties\n",
    "\n",
    "Die Menge der Kunden in dem Alter von `25 - 60` Jahren ist sehr hoch. Dies könnte daran liegen, dass dies die Altersgruppe ist, in der die meisten Menschen arbeiten und somit ein Konto bei der Bank benötigen.\n",
    "\n",
    "Der Job, Ehestatus und der Bildung variiert sehr stark von Kategorie zu Kategorie. Die Trends, ob ein Kunde ein Konto besitzt oder nicht, sind unabhängig von diesen Eigenschaften sehr ähnlich.\n",
    "\n",
    "Die meisten Kunden sind im Bereich *Management*, *Blue Collar* und *Techniker* tätig.\n",
    "\n",
    "Die meisten Kunden sind außerdem verheiratet und haben einen höheren Bildungsabschluss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(25, 25))\n",
    "\n",
    "sns.histplot(df_large, x=\"age\", ax=axs[0][0], kde=True)\n",
    "sns.countplot(x=\"job\", hue=\"y\", data=df_large, ax=axs[0][1])\n",
    "sns.countplot(x=\"marital\", hue=\"y\", data=df_large, ax=axs[1][0])\n",
    "sns.countplot(x=\"education\", hue=\"y\", data=df_large, ax=axs[1][1])\n",
    "\n",
    "axs[0][0].set_title(\"Age\")\n",
    "axs[0][1].set_title(\"Job\")\n",
    "axs[1][0].set_title(\"Marital\")\n",
    "axs[1][1].set_title(\"Education\")\n",
    "\n",
    "axs[0][1].tick_params(axis='x', rotation=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(df_large, x=\"y\", y=\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(df_large, x=\"job\", y=\"age\", hue=\"y\")\n",
    "\n",
    "plt.title(\"Age by Job\")\n",
    "plt.xticks(rotation=35)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loans and Credits\n",
    "\n",
    "Wenn ein Kunde ein `default_credit` haben, gibt es keinen Kunden der ebenfalls ein `term_deposit` hat.\n",
    "\n",
    "Wenn ein Kunde einen Kredit auf sein Haus aufgenommen hat, ist das Verhältnis von Kunden mit einem `term_deposit` leicht höher. Außerdem lässt sich feststellen, dass es mehr Kunden mit einen Kredit auf ihrem Haus gibt, als ohne.\n",
    "\n",
    "Es gibt deutlich mehr Kunden ohne einen `personal_loan` als mit einem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(25, 25))\n",
    "\n",
    "sns.countplot(x=\"default\", hue=\"y\", data=df_large, ax=axs[0][0])\n",
    "sns.countplot(x=\"housing\", hue=\"y\", data=df_large, ax=axs[0][1])\n",
    "sns.countplot(x=\"loan\", hue=\"y\", data=df_large, ax=axs[1][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus der Grafik geht hervor, dass Kunden mit einem hohen Kontostand eher kurze Gespräche führen. Wohingegen Kunden mit wenig Geld auf dem Konto sich in lange Gespräche verwickeln lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"duration\", y=\"balance\", hue=\"marital\", data=df_large)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus den Grafiken geht hervor, dass Kunden mit einer längeren Gesprächsdauer auch eher ein Konto eröffnen. Dem Kontostand ist zu entnehmen, dass Kunden mit mehr Geld auf dem Konto kein neues eröffnen. \n",
    "\n",
    "Es ist anzunehmen, dass Kunden mit mehr Geld schon ein Konto haben und daher kein neues benötigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20,8))\n",
    "\n",
    "sns.boxenplot(df_large, x=\"y\", y=\"duration\", ax=axs[0])\n",
    "sns.boxenplot(df_large, x=\"y\", y=\"balance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df_large, x=\"previous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df_large, x=\"campaign\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Spalte `pdays` bildet ab, wann der letzte Kontakt mit einem Kunden war. Hierbei fällt auf, dass es sich bei `80` % um Neukunden handelt, welche zuvor noch keinen Kontakt mit der Bank hatten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdays_invalide = len(df_large[df_large[\"pdays\"] == -1])\n",
    "\n",
    "print(pdays_invalide / len(df_large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_large, x=\"pdays\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "Die Korrelation zwischen der Dauer des Gesprächs und ob ein Kunde ein Konto eröffnet korrelieren zu stark miteinander. Dies könnte daran liegen, dass die Kunden, die ein Konto eröffnen, länger mit dem Bankberater sprechen, um mehr Informationen zu erhalten. ,\n",
    "\n",
    "Da die Anzahl an Tagen seit dem letzten Kontakt sehr ungleich verteilt ist und die Korrelation gering, wird diese Spalte fallen gelassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_enc.iloc[:, 0:11].corr()\n",
    "mask = np.zeros_like(corr_matrix)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(corr_matrix, mask=mask, square=True, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_corr = []\n",
    "\n",
    "for col in corr_matrix.columns:\n",
    "    for row in corr_matrix.index:\n",
    "        if row != col:\n",
    "            collected_corr.append((col, row, corr_matrix.loc[row, col]))\n",
    "            \n",
    "df_collected_corr = pd.DataFrame(collected_corr, columns=[\"col1\", \"col2\", \"corr\"])\n",
    "df_collected_corr[\"abs_corr\"] = df_collected_corr[\"corr\"].abs()\n",
    "df_collected_corr.sort_values(\"abs_corr\", ascending=False, inplace=True)\n",
    "\n",
    "top_collected = df_collected_corr[:20]\n",
    "bayes_filter_1 = top_collected[\"col1\"].value_counts()\n",
    "bayes_filter_2 = top_collected[\"col2\"].value_counts()\n",
    "\n",
    "bayes_filter = pd.concat([bayes_filter_1, bayes_filter_2], axis=1).fillna(0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_corr = pd.DataFrame(corr_matrix[\"y\"])\n",
    "y_corr[\"corr_abs\"] = y_corr[\"y\"].abs()\n",
    "y_corr = y_corr.sort_values(by=\"corr_abs\", ascending=False)\n",
    "y_corr[1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_naive_bias = y_corr[1:11].index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "Um die Trainingszeit zu verkürzen, wird der kleinere Datensatz (`bank.csv`) für das Training und Modelling verwendet.\n",
    "\n",
    "Für das Training wird ein `80:20` Split gewählt.\n",
    "\n",
    "Da einige Features sehr ungleich verteilt sind, sollte in Erwägung gezogen werden, ob die Daten gesampelt werden sollten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep_model = prepare_pipeline(df_small.copy())\n",
    "df_enc_model = encode_pipeline(df_prep_model.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any(df_enc_model.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_enc_model.drop(\"y\", axis=1)\n",
    "Y_train = df_enc_model[\"y\"]\n",
    "\n",
    "X_train_scaled = StandardScaler().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_count = pd.DataFrame([y_train.value_counts(), y_test.value_counts()], index=[\"train\", \"test\"])\n",
    "df_y_count[\"ratio\"] = df_y_count[1] / df_y_count[0]\n",
    "\n",
    "df_y_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay, confusion_matrix, roc_curve\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "# Lazy Predict is a handy tool to test multiple models\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "collected_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None, predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_clf_results, predictions = lazy_clf.fit(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_clf_results.sort_values(by=\"Accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(25, 25))\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, predictions[\"AdaBoostClassifier\"]), display_labels=[\"no\", \"yes\"]).plot(ax=axs[0][0])\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, predictions[\"RandomForestClassifier\"]), display_labels=[\"no\", \"yes\"]).plot(ax=axs[0][1])\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, predictions[\"GaussianNB\"]), display_labels=[\"no\", \"yes\"]).plot(ax=axs[1][0])\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, predictions[\"SVC\"]), display_labels=[\"no\", \"yes\"]).plot(ax=axs[1][1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_cv_scores = cross_validate(ada_clf, X_train, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"AdaBoost\"] = {key: value.mean() for key, value in ada_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_cv_scores = cross_validate(ada_clf, X_train_scaled, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"AdaBoost_scaled\"] = {key: value.mean() for key, value in ada_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_fit = ada_clf.fit(x_train, y_train).predict(x_test)\n",
    "\n",
    "ada_predict = ada_clf.predict_proba(x_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, ada_predict)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20,8))\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, ada_fit), display_labels=[\"no\", \"yes\"]).plot(ax=axs[0])\n",
    "RocCurveDisplay(fpr=fpr, tpr=tpr).plot(ax=axs[1])\n",
    "plt.plot([0, 1], [0, 1], 'k--')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_cv_scores = cross_validate(log_clf, X_train, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"GradientBoosting\"] = {key: value.mean() for key, value in log_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_cv_scores = cross_validate(log_clf, X_train_scaled, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"GradientBoosting_scaled\"] = {key: value.mean() for key, value in log_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fit = log_clf.fit(x_train, y_train).predict(x_test)\n",
    "\n",
    "log_predict = log_clf.predict_proba(x_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, log_predict)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20,8))\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, log_fit), display_labels=[\"no\", \"yes\"]).plot(ax=axs[0])\n",
    "RocCurveDisplay(fpr=fpr, tpr=tpr).plot(ax=axs[1])\n",
    "plt.plot([0, 1], [0, 1], 'k--')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_cv_scores = cross_validate(rand_clf, X_train, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"RandomForest\"] = {key: value.mean() for key, value in rand_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_cv_scores = cross_validate(rand_clf, X_train_scaled, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"RandomForest_scaled\"] = {key: value.mean() for key, value in rand_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_fit = rand_clf.fit(x_train, y_train).predict(x_test)\n",
    "\n",
    "rand_predict = rand_clf.predict_proba(x_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, rand_predict)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20,8))\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, rand_fit), display_labels=[\"no\", \"yes\"]).plot(ax=axs[0])\n",
    "RocCurveDisplay(fpr=fpr, tpr=tpr).plot(ax=axs[1])\n",
    "plt.plot([0, 1], [0, 1], 'k--')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_cv_scores = cross_validate(gradient_clf, X_train, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"GradientBoosting\"] = {key: value.mean() for key, value in gradient_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_cv_scores = cross_validate(gradient_clf, X_train_scaled, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"GradientBoosting_scaled\"] = {key: value.mean() for key, value in gradient_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_fit = gradient_clf.fit(x_train, y_train).predict(x_test)\n",
    "\n",
    "gradient_predict = gradient_clf.predict_proba(x_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, gradient_predict)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20,8))\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, gradient_fit), display_labels=[\"no\", \"yes\"]).plot(ax=axs[0])\n",
    "RocCurveDisplay(fpr=fpr, tpr=tpr).plot(ax=axs[1])\n",
    "plt.plot([0, 1], [0, 1], 'k--')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cv_scores = cross_validate(svm_clf, X_train, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"SVM\"] = {key: value.mean() for key, value in svm_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cv_scores = cross_validate(svm_clf, X_train_scaled, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"SVM_scaled\"] = {key: value.mean() for key, value in svm_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_test, svm_clf.fit(x_train, y_train).predict(x_test)), display_labels=[\"no\", \"yes\"]).plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes\n",
    "\n",
    "Zuerst wird Naive Bayes auf dem gesamten Datensatz trainiert und anschließend auf dem bereinigten Datensatz. Für den bereinigten Datensatz werden die Spalten mit vielen und hohen Korrelationen entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bayes = X_train.drop(filter_naive_bias.drop([\"pdays\", \"duration\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_cv_scores = cross_validate(gaussian_clf, X_train, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"GaussianNB\"] = {key: value.mean() for key, value in gaussian_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gussian_cv_scores = cross_validate(gaussian_clf, X_train_scaled, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"GaussianNB_scaled\"] = {key: value.mean() for key, value in gussian_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_cv_scores = cross_validate(gaussian_clf, X_train_bayes, Y_train, cv=5, scoring=metrics, return_train_score=True)\n",
    "\n",
    "collected_results[\"GaussianNB_cleaned\"] = {key: value.mean() for key, value in gaussian_cv_scores.items() if key.startswith(\"test_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_fit = gaussian_clf.fit(x_train, y_train).predict(x_test)\n",
    "\n",
    "gussian_predict = gaussian_clf.predict_proba(x_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, gussian_predict)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20,8))\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, gaussian_fit), display_labels=[\"no\", \"yes\"]).plot(ax=axs[0])\n",
    "RocCurveDisplay(fpr=fpr, tpr=tpr).plot(ax=axs[1])\n",
    "plt.plot([0, 1], [0, 1], 'k--')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "Bevor die Spalte `duration` entfernt wurde, war diese das entschiedenste Feature für das Modell. Da jedoch die wahrhaftige `duration` erst am Ende des Gesprächs bekannt ist, kann diese nicht verwendet werden. Außerdem weißt diese eine hohe Korrelation zusammen mit dem Ergebnis `y` auf, da Kunden, die ein Konto eröffnen, länger mit dem Bankberater sprechen.\n",
    "\n",
    "Durch die ungleiche Verteilung von `pdays` wurde diese Spalte ebenfalls fallen gelassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_columns = {\n",
    "    \"test_accuracy\": \"Accuracy\",\n",
    "    \"test_precision\": \"Precision\",\n",
    "    \"test_recall\": \"Recall\",\n",
    "    \"test_f1\": \"F1\",\n",
    "    \"test_roc_auc\": \"ROC AUC\"\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus der Grafik geht hervor, dass die `duration`, `balance`, `age` und `day` am wichtigsten für das Ergebnis des Modells ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_random = pd.DataFrame(rand_clf.fit(X_train, Y_train).feature_importances_, index=X_train.columns, columns=[\"Importance\"]).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "important_random.sort_values(\"Importance\", ascending=False)[:10].plot(kind=\"barh\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der folgenden Tabelle ist zu erkennen, dass (basierend auf der `Accuracy`) **Random Forest** und **Gradient Boosted Trees** am besten abschneiden.\n",
    "\n",
    "Unerwartet ist es, dass der `F1` Score stark von den Vorhersagen von *Lazy Predict* abweicht. Dies deutet auf etwaige Fehler, oder schlechte Hyperparameter während des Trainings, hin. Es kann aber auch der Fall sein, dass *Lazy Predict* fehlerhafte Metriken ausgibt, da *Lazy Predict* nochmal eine Preprocessing Pipeline anwendet.\n",
    "\n",
    "Basierend auf den Confusion Matrix weichen die Prediction von *Lazy Predict* nicht von unseren ab. Dies spricht dafür, dass irgendwo die Metriken falsch berechnet / angegeben werden.\n",
    "\n",
    "Daher werden die Modelle im folgenden ausschließlich nach `ROC AUC` und `Accuracy` bewertet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame.from_dict(collected_results, orient='index').rename(columns=renamed_columns)\n",
    "df_results.sort_values(by=\"Accuracy\", ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Mittels Hyperparameter Tuning ist es uns nicht geglückt das Resultat für Gradient Boosted Trees zu verbessern.\n",
    "\n",
    "Dazu sei gesagt, dass die optimalen Hyperparameter stark von dem Score abhängen, welcher optimiert werden soll. Wenn wir nach `F1` optimieren, ist eine größere Anzahl an `n_estimators` und `max_depth` besser. Bei der `Accuracy` ist dies genau Umgekehrt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_clf_grid = GradientBoostingClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    gradient_clf_grid,\n",
    "    param_grid={\n",
    "        \"n_estimators\": [30, 40, 50],\n",
    "        \"max_depth\": [2, 3, 4],\n",
    "        \"min_samples_split\": [2, 3],\n",
    "    },\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rand_grid = grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rand_grid.best_estimator_)\n",
    "print(rand_grid.best_params_)\n",
    "print(rand_grid.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "00155b37fbb991365d0ee05c40a31a80e0b75de72a8bd7547540e678c5c3c0a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
